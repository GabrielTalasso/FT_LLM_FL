{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49c2748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel.talasso/FT_LLM_FL/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from math import floor\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "from peft import get_peft_model, get_peft_model_state_dict, set_peft_model_state_dict, prepare_model_for_kbit_training\n",
    "\n",
    "from utils import *\n",
    "from utils.utils import default_evaluation, save_dataset_test\n",
    "\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Optional\n",
    "from transformers import HfArgumentParser, TrainingArguments, BitsAndBytesConfig\n",
    "from peft import LoraConfig\n",
    "import os\n",
    "import json\n",
    "from accelerate import Accelerator\n",
    "import torch\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a961e723",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ade61c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'multitask'\n",
    "model_name = 'HuggingFaceTB/SmolLM-135M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bc41d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/gabriel.talasso/.cache/huggingface/modules/datasets_modules/datasets/Samsung--samsum/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e (last modified on Tue Mar 11 13:33:01 2025) since it couldn't be found locally at Samsung/samsum, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/gabriel.talasso/.cache/huggingface/modules/datasets_modules/datasets/Harvard--gigaword/cd40ed63b2731b6da1f321fba3f70998c2d7de54730f50e0c20f6ac37f323a40 (last modified on Tue Mar 11 13:37:41 2025) since it couldn't be found locally at Harvard/gigaword, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Splited into TRAIN: 71668 and TEST: 17917\n"
     ]
    }
   ],
   "source": [
    "dataset, dataset_test = get_dataset(dataset_name, None, 0.8)\n",
    "dataset =      process_sft_dataset(dataset_name, dataset,      400000)\n",
    "dataset_test = process_sft_dataset(dataset_name, dataset_test, 400000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a291b1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_datasets = []\n",
    "tasks = ['boolq', 'gigaword', 'samsum', 'webnlg']\n",
    "n_clients_in_cluster = 4 // len(tasks)\n",
    "\n",
    "for i in range(4):\n",
    "    task = tasks[i // n_clients_in_cluster]\n",
    "    cluster_dataset = dataset.filter(lambda x: x['task'] == task)\n",
    "    cluster_dataset = cluster_dataset.shuffle(seed=0)\n",
    "\n",
    "    local_datasets.append(cluster_dataset.shard(n_clients_in_cluster, i % n_clients_in_cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcd8f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b7d4a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_datasets_test = []\n",
    "for i in range(4):\n",
    "    task = tasks[i // n_clients_in_cluster]\n",
    "    cluster_dataset_test = dataset_test.filter(lambda x: x['task'] == task)\n",
    "    cluster_dataset_test = cluster_dataset_test.shuffle(seed=0)\n",
    "\n",
    "    aux = cluster_dataset_test.shard(n_clients_in_cluster, i % n_clients_in_cluster)\n",
    "    aux = aux.select(range(EVAL_SIZE))  # Limit to 1000 samples for testing\n",
    "    local_datasets_test.append(aux)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aec9e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "# Copy the model to each device\n",
    "device_map = {\"\": Accelerator().local_process_index}\n",
    "torch_dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ce56386",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f63ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_and_tokenizer():\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=device_map,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch_dtype,\n",
    "    )\n",
    "    print(f\"Model loaded from {model_name}\")\n",
    "\n",
    "\n",
    "    model = prepare_model_for_kbit_training(\n",
    "                model, use_gradient_checkpointing=True\n",
    "            )\n",
    "\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "\n",
    "    model.enable_input_require_grads()\n",
    "\n",
    "    # ===== Define the global and local models =====\n",
    "    global_dict = copy.deepcopy(get_peft_model_state_dict(model))\n",
    "    local_dict_list = [copy.deepcopy(global_dict) for i in range(4)]\n",
    "\n",
    "    # ===== Define the tokenizer =====\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, padding_side=\"right\")\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.unk_token   # following vicuna\n",
    "\n",
    "    if tokenizer.eos_token == tokenizer.unk_token or tokenizer.pad_token == tokenizer.eos_token:\n",
    "        tokenizer.add_special_tokens({'pad_token': '<pad>'})\n",
    "        print(f\"Pad token is set to {tokenizer.pad_token}.\")\n",
    "\n",
    "    print('Special tokens:', tokenizer.special_tokens_map)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d38ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps=100\n",
    "num_train_epochs=1\n",
    "num_rounds=100\n",
    "eval_round=\"10,25,50,100\"\n",
    "batch_size=16\n",
    "batch_size_eval=128\n",
    "gradient_accumulation_steps=1\n",
    "seq_length=1024\n",
    "num_clients=8\n",
    "sample_clients=8\n",
    "lora_r=8\n",
    "lora_alpha=16  # twice of lora_r\n",
    "lr=5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d604259",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'output_centralized_tests50'\n",
    "eval_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47ab01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        learning_rate=lr,\n",
    "        logging_steps=10,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        max_steps=max_steps,\n",
    "        report_to=None,\n",
    "        save_steps=1000,\n",
    "        save_total_limit=10,\n",
    "        push_to_hub=False,\n",
    "        hub_model_id=None,\n",
    "        gradient_checkpointing=True,\n",
    "        lr_scheduler_type=\"constant\",\n",
    "        #max_seq_length=script_args.seq_length,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63fc7a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from HuggingFaceTB/SmolLM-135M\n",
      "trainable params: 460,800 || all params: 134,975,808 || trainable%: 0.3414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad token is set to <pad>.\n",
      "Special tokens: {'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<pad>', 'additional_special_tokens': ['<|endoftext|>', '<|im_start|>', '<|im_end|>', '<repo_name>', '<reponame>', '<file_sep>', '<filename>', '<gh_stars>', '<issue_start>', '<issue_comment>', '<issue_closed>', '<jupyter_start>', '<jupyter_text>', '<jupyter_code>', '<jupyter_output>', '<jupyter_script>', '<empty_output>']}\n"
     ]
    }
   ],
   "source": [
    "_,  tokenizer = get_model_and_tokenizer()\n",
    "formatting_prompts_func, response_template = get_formatting_prompts_func('alpaca', tokenizer.eos_token)\n",
    "if response_template:\n",
    "    response_template_ids = tokenizer.encode(response_template, add_special_tokens=False)[2:]   # Now we have it like in the dataset texts: `[2277, 29937, 4007, 22137, 29901]` for Llama2\n",
    "    data_collator = DataCollatorForCompletionOnlyLM(response_template_ids, tokenizer=tokenizer)\n",
    "    packing = False\n",
    "else:\n",
    "    data_collator = None\n",
    "    packing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27ebe06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_evaluation(model, tokenizer, dataset, client_id, round, formatting_prompts_func, script_args, cluster_id=None):\n",
    "    \"\"\"\n",
    "    Default evaluation function to compute model responses and ROUGE scores.\n",
    "    \"\"\"\n",
    "    print(\"Evaluating model...\")\n",
    "    # Apply template to dataset\n",
    "    dataset = utils.apply_template_to_dataset(dataset, formatting_prompts_func)\n",
    "    dataset_length = len(dataset)\n",
    "    eval_responses = utils.get_model_responses(model, tokenizer, dataset, batch_size=eval_batch_size)\n",
    "    dataset_with_responses = dataset.select(range(len(dataset)))\n",
    "    dataset_with_responses = dataset_with_responses.add_column('model_responses', eval_responses)\n",
    "    scores = utils.calcule_rogue1(eval_responses, dataset_with_responses)\n",
    "    print(f\"Evaluation scores: {scores}\")\n",
    "\n",
    "    #verify output directory\n",
    "    if not os.path.exists(os.path.join(output_dir, \"evals\")):\n",
    "        os.makedirs(os.path.join(output_dir, \"evals\"))\n",
    "    # Save evaluation results\n",
    "    with open(os.path.join(output_dir, f\"evals/rouge_client_{client_id}_cluster_{cluster_id}_round_{round}.json\"), 'w') as f:\n",
    "        scores['dataset_length'] = dataset_length\n",
    "        json.dump(scores, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73145043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file, save_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "531ada6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from HuggingFaceTB/SmolLM-135M\n",
      "trainable params: 460,800 || all params: 134,975,808 || trainable%: 0.3414\n",
      "Pad token is set to <pad>.\n",
      "Special tokens: {'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<pad>', 'additional_special_tokens': ['<|endoftext|>', '<|im_start|>', '<|im_end|>', '<repo_name>', '<reponame>', '<file_sep>', '<filename>', '<gh_stars>', '<issue_start>', '<issue_comment>', '<issue_closed>', '<jupyter_start>', '<jupyter_text>', '<jupyter_code>', '<jupyter_output>', '<jupyter_script>', '<empty_output>']}\n",
      "Evaluating Pretrained Model on Dataset({\n",
      "    features: ['question', 'answer', 'passage', 'instruction', 'response', 'task', 'gem_id', 'gem_parent_id', 'input', 'target', 'references', 'category', 'webnlg_id', 'id', 'dialogue', 'summary', 'document'],\n",
      "    num_rows: 1000\n",
      "}) for task 0\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [01:23<09:44, 83.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [02:44<08:12, 82.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [04:23<07:29, 89.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [06:10<06:26, 96.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [07:31<04:33, 91.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [08:44<02:49, 84.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [10:05<01:23, 83.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [11:10<00:00, 83.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation scores: {'rouge1': np.float64(5.613313226800335e-05), 'rouge2': np.float64(0.0), 'rougeL': np.float64(5.8149443965857975e-05), 'rougeLsum': np.float64(5.7458162965534884e-05)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 01:45, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.672300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.136100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.794800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.354700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.339300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.362600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.353900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.338400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.314200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.326600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel.talasso/FT_LLM_FL/.venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel.talasso/FT_LLM_FL/.venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval_posting model...\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel.talasso/FT_LLM_FL/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      " 12%|█▎        | 1/8 [00:04<00:28,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:07<00:22,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:12<00:22,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:18<00:20,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [00:22<00:13,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [00:25<00:08,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [00:29<00:03,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:32<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation scores: {'rouge1': np.float64(0.628), 'rouge2': np.float64(0.0), 'rougeL': np.float64(0.627), 'rougeLsum': np.float64(0.628)}\n",
      "Cleaning up...\n",
      "Done with client 0\n",
      "Model loaded from HuggingFaceTB/SmolLM-135M\n",
      "trainable params: 460,800 || all params: 134,975,808 || trainable%: 0.3414\n",
      "Pad token is set to <pad>.\n",
      "Special tokens: {'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<pad>', 'additional_special_tokens': ['<|endoftext|>', '<|im_start|>', '<|im_end|>', '<repo_name>', '<reponame>', '<file_sep>', '<filename>', '<gh_stars>', '<issue_start>', '<issue_comment>', '<issue_closed>', '<jupyter_start>', '<jupyter_text>', '<jupyter_code>', '<jupyter_output>', '<jupyter_script>', '<empty_output>']}\n",
      "Evaluating Pretrained Model on Dataset({\n",
      "    features: ['question', 'answer', 'passage', 'instruction', 'response', 'task', 'gem_id', 'gem_parent_id', 'input', 'target', 'references', 'category', 'webnlg_id', 'id', 'dialogue', 'summary', 'document'],\n",
      "    num_rows: 1000\n",
      "}) for task 1\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 4674.26 examples/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:49<05:48, 49.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [01:40<05:03, 50.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [02:31<04:11, 50.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [03:20<03:20, 50.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [04:11<02:30, 50.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [05:00<01:40, 50.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [05:50<00:49, 49.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [06:34<00:00, 49.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation scores: {'rouge1': np.float64(0.008190108799093227), 'rouge2': np.float64(0.0028405914700258142), 'rougeL': np.float64(0.007499066123792117), 'rougeLsum': np.float64(0.007336903565406592)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:34, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.680300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.239500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.191600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.192300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.093700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.917900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.740600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.085200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.990900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel.talasso/FT_LLM_FL/.venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel.talasso/FT_LLM_FL/.venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval_posting model...\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/gabriel.talasso/FT_LLM_FL/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:51<05:58, 51.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [01:43<05:09, 51.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [02:33<04:16, 51.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [03:25<03:25, 51.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [04:16<02:33, 51.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [05:07<01:42, 51.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [05:58<00:51, 51.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [06:43<00:00, 50.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation scores: {'rouge1': np.float64(0.24244135306916573), 'rouge2': np.float64(0.08746501830972976), 'rougeL': np.float64(0.22105938919622847), 'rougeLsum': np.float64(0.22073849394710499)}\n",
      "Cleaning up...\n",
      "Done with client 1\n",
      "Model loaded from HuggingFaceTB/SmolLM-135M\n",
      "trainable params: 460,800 || all params: 134,975,808 || trainable%: 0.3414\n",
      "Pad token is set to <pad>.\n",
      "Special tokens: {'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<pad>', 'additional_special_tokens': ['<|endoftext|>', '<|im_start|>', '<|im_end|>', '<repo_name>', '<reponame>', '<file_sep>', '<filename>', '<gh_stars>', '<issue_start>', '<issue_comment>', '<issue_closed>', '<jupyter_start>', '<jupyter_text>', '<jupyter_code>', '<jupyter_output>', '<jupyter_script>', '<empty_output>']}\n",
      "Evaluating Pretrained Model on Dataset({\n",
      "    features: ['question', 'answer', 'passage', 'instruction', 'response', 'task', 'gem_id', 'gem_parent_id', 'input', 'target', 'references', 'category', 'webnlg_id', 'id', 'dialogue', 'summary', 'document'],\n",
      "    num_rows: 1000\n",
      "}) for task 2\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 3058.84 examples/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [01:53<13:17, 113.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [03:47<11:22, 113.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [05:18<08:35, 103.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [07:10<07:06, 106.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [09:03<05:26, 108.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [10:38<03:28, 104.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [12:51<01:53, 113.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [14:26<00:00, 108.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation scores: {'rouge1': np.float64(0.019729008131734126), 'rouge2': np.float64(0.004577493815434987), 'rougeL': np.float64(0.01684521207722834), 'rougeLsum': np.float64(0.016765502998962838)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 02:40, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.943800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.380200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.165700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.068400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.089800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.092400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.057500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.945100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.958400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.964400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel.talasso/FT_LLM_FL/.venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel.talasso/FT_LLM_FL/.venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval_posting model...\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel.talasso/FT_LLM_FL/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      " 12%|█▎        | 1/8 [01:53<13:15, 113.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [03:46<11:19, 113.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [05:16<08:32, 102.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [07:08<07:05, 106.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [09:01<05:25, 108.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [10:36<03:27, 103.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [12:49<01:53, 113.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [14:23<00:00, 107.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation scores: {'rouge1': np.float64(0.32945939983858774), 'rouge2': np.float64(0.12058495893470517), 'rougeL': np.float64(0.26585045139157215), 'rougeLsum': np.float64(0.2662275709321097)}\n",
      "Cleaning up...\n",
      "Done with client 2\n",
      "Model loaded from HuggingFaceTB/SmolLM-135M\n",
      "trainable params: 460,800 || all params: 134,975,808 || trainable%: 0.3414\n",
      "Pad token is set to <pad>.\n",
      "Special tokens: {'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<pad>', 'additional_special_tokens': ['<|endoftext|>', '<|im_start|>', '<|im_end|>', '<repo_name>', '<reponame>', '<file_sep>', '<filename>', '<gh_stars>', '<issue_start>', '<issue_comment>', '<issue_closed>', '<jupyter_start>', '<jupyter_text>', '<jupyter_code>', '<jupyter_output>', '<jupyter_script>', '<empty_output>']}\n",
      "Evaluating Pretrained Model on Dataset({\n",
      "    features: ['question', 'answer', 'passage', 'instruction', 'response', 'task', 'gem_id', 'gem_parent_id', 'input', 'target', 'references', 'category', 'webnlg_id', 'id', 'dialogue', 'summary', 'document'],\n",
      "    num_rows: 1000\n",
      "}) for task 3\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 4160.76 examples/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:52<06:08, 52.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [01:49<05:29, 54.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [02:44<04:35, 55.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [03:42<03:44, 56.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [04:36<02:46, 55.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [05:34<01:52, 56.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [06:31<00:56, 56.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [07:19<00:00, 54.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation scores: {'rouge1': np.float64(0.019139384043698034), 'rouge2': np.float64(0.004979117700138286), 'rougeL': np.float64(0.01692801179210806), 'rougeLsum': np.float64(0.016592589075911525)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 01:02, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.141600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.642100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.544600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.423300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.414100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.321300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.304500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.301200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.205800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel.talasso/FT_LLM_FL/.venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel.talasso/FT_LLM_FL/.venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval_posting model...\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel.talasso/FT_LLM_FL/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      " 12%|█▎        | 1/8 [00:53<06:12, 53.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [01:01<02:39, 26.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [01:56<03:19, 39.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [02:54<03:08, 47.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [03:00<01:36, 32.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [03:59<01:22, 41.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [04:06<00:30, 30.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [04:14<00:00, 31.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation scores: {'rouge1': np.float64(0.5806225344910934), 'rouge2': np.float64(0.32621896396061323), 'rougeL': np.float64(0.4477046489718357), 'rougeLsum': np.float64(0.4475128572790117)}\n",
      "Cleaning up...\n",
      "Done with client 3\n"
     ]
    }
   ],
   "source": [
    "for i, local_dataset in enumerate(local_datasets):\n",
    "\n",
    "    model, tokenizer = get_model_and_tokenizer()\n",
    "\n",
    "    test_dataset = local_datasets_test[i]\n",
    "\n",
    "    print(f\"Evaluating Pretrained Model on {test_dataset} for task {i}\")\n",
    "    default_evaluation(\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer,\n",
    "                    dataset=test_dataset,\n",
    "                    client_id=i,\n",
    "                    round=0, #with respect to model from the previous round\n",
    "                    formatting_prompts_func=formatting_prompts_func,\n",
    "                    script_args=None,\n",
    "                    cluster_id=0,\n",
    "                )\n",
    "    \n",
    "    trainer = SFTTrainer(\n",
    "            model=model,\n",
    "            processing_class=tokenizer,\n",
    "            args=training_args,\n",
    "            #max_seq_length=script_args.seq_length,\n",
    "            train_dataset=local_dataset,\n",
    "            formatting_func=formatting_prompts_func,\n",
    "            data_collator=data_collator,\n",
    "            #packing=packing,\n",
    "            #dataset_text_field=dataset_text_field,\n",
    "        )\n",
    "\n",
    "    print('Training model...')\n",
    "    trainer.train()\n",
    "\n",
    "    print('Saving model...')\n",
    "    model.save_pretrained(os.path.join(output_dir, f\"model_client_{i}_cluster_0_round_0\"))\n",
    "\n",
    "    print('Eval_posting model...')\n",
    "    default_evaluation(\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer,\n",
    "                    dataset=test_dataset,\n",
    "                    client_id=i,\n",
    "                    round=1, \n",
    "                    formatting_prompts_func=formatting_prompts_func,\n",
    "                    script_args=None,\n",
    "                    cluster_id=0,\n",
    "                )\n",
    "    \n",
    "    print('Cleaning up...')\n",
    "    del model\n",
    "    del tokenizer\n",
    "    torch.cuda.empty_cache()\n",
    "    print('Done with client', i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98188d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from HuggingFaceTB/SmolLM-135M\n",
      "trainable params: 460,800 || all params: 134,975,808 || trainable%: 0.3414\n",
      "Pad token is set to <pad>.\n",
      "Special tokens: {'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<pad>', 'additional_special_tokens': ['<|endoftext|>', '<|im_start|>', '<|im_end|>', '<repo_name>', '<reponame>', '<file_sep>', '<filename>', '<gh_stars>', '<issue_start>', '<issue_comment>', '<issue_closed>', '<jupyter_start>', '<jupyter_text>', '<jupyter_code>', '<jupyter_output>', '<jupyter_script>', '<empty_output>']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 01:33, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.738400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.292700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.157100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.051300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.931400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.932700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.862400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.885100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.970500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.923200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel.talasso/FT_LLM_FL/.venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel.talasso/FT_LLM_FL/.venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval_posting model...\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel.talasso/FT_LLM_FL/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      " 12%|█▎        | 1/8 [00:06<00:45,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:11<00:33,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:17<00:30,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:28<00:31,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [01:49<01:42, 34.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [01:54<00:48, 24.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [01:59<00:18, 18.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [02:04<00:00, 15.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation scores: {'rouge1': np.float64(0.007333333333333333), 'rouge2': np.float64(0.0), 'rougeL': np.float64(0.007333333333333333), 'rougeLsum': np.float64(0.007)}\n",
      "Eval_posting model...\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:50<05:52, 50.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [01:41<05:06, 51.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [02:32<04:15, 51.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [03:24<03:24, 51.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [04:15<02:33, 51.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [05:06<01:42, 51.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [05:57<00:51, 51.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [06:45<00:00, 50.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation scores: {'rouge1': np.float64(0.23333589335375696), 'rouge2': np.float64(0.0726234653157449), 'rougeL': np.float64(0.20854175744394338), 'rougeLsum': np.float64(0.20896759148525829)}\n",
      "Eval_posting model...\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [01:53<13:14, 113.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [03:46<11:20, 113.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [05:16<08:33, 102.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [07:08<07:05, 106.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [09:01<05:25, 108.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [10:36<03:28, 104.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [12:49<01:53, 113.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [14:24<00:00, 108.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation scores: {'rouge1': np.float64(0.2896599169603845), 'rouge2': np.float64(0.10003220223416201), 'rougeL': np.float64(0.23524857447853081), 'rougeLsum': np.float64(0.23578062267728153)}\n",
      "Eval_posting model...\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:53<06:15, 53.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [01:50<05:33, 55.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [01:56<02:45, 33.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [02:55<02:51, 42.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [03:50<02:21, 47.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [03:58<01:08, 34.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [04:06<00:25, 25.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [04:15<00:00, 31.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation scores: {'rouge1': np.float64(0.557715562030906), 'rouge2': np.float64(0.29954128112309997), 'rougeL': np.float64(0.4342804457957795), 'rougeLsum': np.float64(0.4342313387815264)}\n",
      "Cleaning up...\n",
      "Done with client 3\n"
     ]
    }
   ],
   "source": [
    "#Mixturing all datasets\n",
    "\n",
    "dataset.shuffle(seed=0)\n",
    "dataset = dataset.select(range(10000))  # Limit to 1000 samples for training\n",
    "\n",
    "model, tokenizer = get_model_and_tokenizer()\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        processing_class=tokenizer,\n",
    "        args=training_args,\n",
    "        #max_seq_length=script_args.seq_length,\n",
    "        train_dataset=dataset,\n",
    "        formatting_func=formatting_prompts_func,\n",
    "        data_collator=data_collator,\n",
    "        #packing=packing,\n",
    "        #dataset_text_field=dataset_text_field,\n",
    "    )\n",
    "\n",
    "print('Training model...')\n",
    "trainer.train()\n",
    "\n",
    "print('Saving model...')\n",
    "model.save_pretrained(os.path.join(output_dir, f\"model_client_all_cluster_0_round_0\"))\n",
    "\n",
    "for i, test_dataset in enumerate(local_datasets_test):\n",
    "\n",
    "    print('Eval_posting model...')\n",
    "    default_evaluation(\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer,\n",
    "                    dataset=test_dataset,\n",
    "                    client_id='all',\n",
    "                    round=1, \n",
    "                    formatting_prompts_func=formatting_prompts_func,\n",
    "                    script_args=None,\n",
    "                    cluster_id=i,\n",
    "                )\n",
    "\n",
    "print('Cleaning up...')\n",
    "del model\n",
    "del tokenizer\n",
    "torch.cuda.empty_cache()\n",
    "print('Done with client', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89505a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_single_task = []\n",
    "\n",
    "for i in range(4):\n",
    "    with open(os.path.join(output_dir, f\"evals/rouge_client_{i}_cluster_0_round_1.json\"), 'r') as f:\n",
    "        scores = json.load(f)\n",
    "        results_single_task.append(scores['rouge1'])\n",
    "\n",
    "results_multi_task = []\n",
    "for i in range(4):\n",
    "    with open(os.path.join(output_dir, f\"evals/rouge_client_all_cluster_{i}_round_1.json\"), 'r') as f:\n",
    "        scores = json.load(f)\n",
    "        results_multi_task.append(scores['rouge1'])\n",
    "\n",
    "results_pretrained = []\n",
    "for i in range(4):\n",
    "    with open(os.path.join(output_dir, f\"evals/rouge_client_{i}_cluster_0_round_0.json\"), 'r') as f:\n",
    "        scores = json.load(f)\n",
    "        results_pretrained.append(scores['rouge1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc3b9988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efb01ca0370>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = np.arange(len(tasks))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "plt.bar(x - width, results_single_task, width, label='Single Task', color='#1f77b4')\n",
    "plt.bar(x, results_multi_task, width, label='Multi Task', color='#ff7f0e')\n",
    "plt.bar(x + width, results_pretrained, width, label='Pretrained', color='#2ca02c')\n",
    "\n",
    "plt.xlabel('Tasks')\n",
    "plt.ylabel('ROUGE-1 Score')\n",
    "plt.title('ROUGE-1 Scores for Single Task, Multi Task, and Pretrained Models')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58e688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file, save_file\n",
    "\n",
    "lora_task1_path = 'output_centralized_tests50/model_client_0_cluster_0_round_0/adapter_model.safetensors'\n",
    "lora_task2_path = 'output_centralized_tests50/model_client_1_cluster_0_round_0/adapter_model.safetensors'\n",
    "lora_task3_path = 'output_centralized_tests50/model_client_2_cluster_0_round_0/adapter_model.safetensors'\n",
    "lora_task4_path = 'output_centralized_tests50/model_client_3_cluster_0_round_0/adapter_model.safetensors'\n",
    "\n",
    "lora_paths = [lora_task1_path, lora_task2_path, lora_task3_path, lora_task4_path]\n",
    "\n",
    "# Mean of A matrices\n",
    "lora_a_tensors = {}\n",
    "for lora_path in lora_paths:\n",
    "    lora_state_dict = load_file(lora_path)\n",
    "    for key in lora_state_dict:\n",
    "        if 'lora_A' in key:\n",
    "            if key not in lora_a_tensors:\n",
    "                lora_a_tensors[key] = []\n",
    "            lora_a_tensors[key].append(lora_state_dict[key])\n",
    "\n",
    "# Calculate mean for each lora_A matrix\n",
    "lora_a_means = {}\n",
    "for key, tensors in lora_a_tensors.items():\n",
    "    stacked = torch.stack(tensors)\n",
    "    lora_a_means[key] = torch.mean(stacked, dim=0)\n",
    "\n",
    "# Create new adapters (Specific B with aggregated A matrices)\n",
    "for lora_path in lora_paths:\n",
    "    lora_state_dict = load_file(lora_path)\n",
    "    lora_aggregated_state_dict = {}\n",
    "    \n",
    "    # Copy all tensors from the original state dict\n",
    "    for key in lora_state_dict:\n",
    "        if 'lora_B' in key:\n",
    "            # Keep original B matrices\n",
    "            lora_aggregated_state_dict[key] = lora_state_dict[key]\n",
    "        elif 'lora_A' in key:\n",
    "            # Replace with mean A matrices\n",
    "            lora_aggregated_state_dict[key] = lora_a_means[key]\n",
    "        else:\n",
    "            # Copy other tensors (like bias terms if any)\n",
    "            lora_aggregated_state_dict[key] = lora_state_dict[key]\n",
    "            \n",
    "    # Save the aggregated LoRA state dict\n",
    "    save_path = os.path.join(os.path.dirname(lora_path), 'lora_SA.safetensors')\n",
    "    save_file(lora_aggregated_state_dict, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceffc6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from HuggingFaceTB/SmolLM-135M\n",
      "trainable params: 3,686,400 || all params: 138,201,408 || trainable%: 2.6674\n",
      "Pad token is set to <pad>.\n",
      "Special tokens: {'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<pad>', 'additional_special_tokens': ['<|endoftext|>', '<|im_start|>', '<|im_end|>', '<repo_name>', '<reponame>', '<file_sep>', '<filename>', '<gh_stars>', '<issue_start>', '<issue_comment>', '<issue_closed>', '<jupyter_start>', '<jupyter_text>', '<jupyter_code>', '<jupyter_output>', '<jupyter_script>', '<empty_output>']}\n",
      "Eval_posting model...\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [01:23<09:43, 83.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [02:44<08:10, 81.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [04:23<07:28, 89.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [06:10<06:26, 96.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [07:31<04:32, 90.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [08:44<02:49, 84.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [10:05<01:23, 83.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [11:10<00:00, 83.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation scores: {'rouge1': np.float64(0.018755516603976778), 'rouge2': np.float64(0.0), 'rougeL': np.float64(0.018719413459389322), 'rougeLsum': np.float64(0.018724275346090617)}\n",
      "Cleaning up...\n",
      "Done with client 0\n",
      "Model loaded from HuggingFaceTB/SmolLM-135M\n",
      "trainable params: 3,686,400 || all params: 138,201,408 || trainable%: 2.6674\n",
      "Pad token is set to <pad>.\n",
      "Special tokens: {'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<pad>', 'additional_special_tokens': ['<|endoftext|>', '<|im_start|>', '<|im_end|>', '<repo_name>', '<reponame>', '<file_sep>', '<filename>', '<gh_stars>', '<issue_start>', '<issue_comment>', '<issue_closed>', '<jupyter_start>', '<jupyter_text>', '<jupyter_code>', '<jupyter_output>', '<jupyter_script>', '<empty_output>']}\n",
      "Eval_posting model...\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:50<05:53, 50.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [01:43<05:12, 52.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [02:34<04:18, 51.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [03:25<03:25, 51.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [04:16<02:33, 51.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [05:07<01:42, 51.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [05:59<00:51, 51.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [06:43<00:00, 50.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation scores: {'rouge1': np.float64(0.11651993515332121), 'rouge2': np.float64(0.10428218595951291), 'rougeL': np.float64(0.11646213980832595), 'rougeLsum': np.float64(0.1165580211200409)}\n",
      "Cleaning up...\n",
      "Done with client 1\n",
      "Model loaded from HuggingFaceTB/SmolLM-135M\n",
      "trainable params: 3,686,400 || all params: 138,201,408 || trainable%: 2.6674\n",
      "Pad token is set to <pad>.\n",
      "Special tokens: {'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<pad>', 'additional_special_tokens': ['<|endoftext|>', '<|im_start|>', '<|im_end|>', '<repo_name>', '<reponame>', '<file_sep>', '<filename>', '<gh_stars>', '<issue_start>', '<issue_comment>', '<issue_closed>', '<jupyter_start>', '<jupyter_text>', '<jupyter_code>', '<jupyter_output>', '<jupyter_script>', '<empty_output>']}\n",
      "Eval_posting model...\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [01:57<13:41, 117.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [03:55<11:46, 117.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [05:32<09:01, 108.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [07:31<07:29, 112.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [09:30<05:44, 114.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [11:11<03:40, 110.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [13:29<01:59, 119.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [15:09<00:00, 113.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation scores: {'rouge1': np.float64(0.2710980170221315), 'rouge2': np.float64(0.26287366475663976), 'rougeL': np.float64(0.2707099758943961), 'rougeLsum': np.float64(0.2708967245375258)}\n",
      "Cleaning up...\n",
      "Done with client 2\n",
      "Model loaded from HuggingFaceTB/SmolLM-135M\n",
      "trainable params: 3,686,400 || all params: 138,201,408 || trainable%: 2.6674\n",
      "Pad token is set to <pad>.\n",
      "Special tokens: {'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<pad>', 'additional_special_tokens': ['<|endoftext|>', '<|im_start|>', '<|im_end|>', '<repo_name>', '<reponame>', '<file_sep>', '<filename>', '<gh_stars>', '<issue_start>', '<issue_comment>', '<issue_closed>', '<jupyter_start>', '<jupyter_text>', '<jupyter_code>', '<jupyter_output>', '<jupyter_script>', '<empty_output>']}\n",
      "Eval_posting model...\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:59<06:54, 59.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [02:04<06:15, 62.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [03:04<05:07, 61.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [04:09<04:11, 62.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [05:10<03:06, 62.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [06:18<02:08, 64.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [07:21<01:03, 63.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses for batch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [08:14<00:00, 61.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation scores: {'rouge1': np.float64(0.30830521425298796), 'rouge2': np.float64(0.2969198395903758), 'rougeL': np.float64(0.3085428098071732), 'rougeLsum': np.float64(0.3084606967723609)}\n",
      "Cleaning up...\n",
      "Done with client 3\n"
     ]
    }
   ],
   "source": [
    "#test all SA with their respective test_local_dataset\n",
    "\n",
    "for i, test_dataset in enumerate(local_datasets_test):\n",
    "    lora_sa_path = f'output_centralized_tests50/model_client_{i}_cluster_0_round_0/lora_SA.safetensors'\n",
    "    lora_sa_state_dict = load_file(lora_sa_path)\n",
    "\n",
    "    model, tokenizer = get_model_and_tokenizer()\n",
    "    model.load_state_dict(lora_sa_state_dict, strict=False)\n",
    "\n",
    "    print('Eval_posting model...')\n",
    "    default_evaluation(\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer,\n",
    "                    dataset=test_dataset,\n",
    "                    client_id='SA',\n",
    "                    round=1, \n",
    "                    formatting_prompts_func=formatting_prompts_func,\n",
    "                    script_args=None,\n",
    "                    cluster_id=i,\n",
    "                )\n",
    "\n",
    "    print('Cleaning up...')\n",
    "    del model\n",
    "    del tokenizer\n",
    "    torch.cuda.empty_cache()\n",
    "    print('Done with client', i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3a9381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

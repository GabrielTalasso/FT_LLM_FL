{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel.talasso/FT_LLM_FL/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-03 12:51:34,486] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "sys.path.append(\".\")\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "from datasets import load_dataset\n",
    "from accelerate import Accelerator\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.template import TEMPLATE_DICT\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = TEMPLATE_DICT['alpaca'][0]\n",
    "MODEL_NAME = 'TinyLlama/TinyLlama_v1.1'\n",
    "DATASET_NAME = \"CohereForAI/aya_dataset\"\n",
    "DEVICE = 'cuda:0'\n",
    "EVALSET_LEN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20240923122624/cluster_0_checkpoint-200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, MODEL_NAME, DEVICE):\n",
    "    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.float16,\n",
    "                                                    quantization_config = BitsAndBytesConfig(\n",
    "                                                                            load_in_4bit=True,\n",
    "                                                                            bnb_4bit_use_double_quant=True,\n",
    "                                                                            bnb_4bit_quant_type=\"nf4\",\n",
    "                                                                            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                                                                        ),\n",
    "                                                    device_map={\"\": Accelerator().local_process_index})\n",
    "\n",
    "    model = PeftModel.from_pretrained(model, path).to(DEVICE)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, device=DEVICE, use_fast=False, padding_side=\"right\")\n",
    "    tokenizer.pad_token = tokenizer.unk_token\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "#model, tokenizer = load_model(path, MODEL_NAME, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eval_data(DATASET_NAME, EVALSET_LEN, languages):\n",
    "    \n",
    "    dataset = load_dataset(DATASET_NAME, split=\"train\", )\n",
    "    dataset = dataset.filter(lambda x: x['language'] in ['English', 'Swedish', 'German', 'Portuguese', 'Spanish'])\n",
    "    dataset_splited = dataset.train_test_split(test_size= 0.2, seed=0)\n",
    "    dataset_test = dataset_splited['test']\n",
    "    dataset = dataset_test.filter(lambda x: x['language'] in languages)\n",
    "    dataset_len = min(len(dataset), EVALSET_LEN)\n",
    "    dataset = dataset.select(range(dataset_len))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples[\"inputs\"],   padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    targets = tokenizer(examples[\"targets\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
    "        \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
    "        \"labels\": targets[\"input_ids\"].squeeze()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/gabriel.talasso/.cache/huggingface/datasets/CohereForAI___parquet/default-dc0ecc36655ce556/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "Loading cached processed dataset at /home/gabriel.talasso/.cache/huggingface/datasets/CohereForAI___parquet/default-dc0ecc36655ce556/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-a43a64b8b3c754cd.arrow\n",
      "Loading cached split indices for dataset at /home/gabriel.talasso/.cache/huggingface/datasets/CohereForAI___parquet/default-dc0ecc36655ce556/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-cca2a273063fd6b6.arrow and /home/gabriel.talasso/.cache/huggingface/datasets/CohereForAI___parquet/default-dc0ecc36655ce556/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-d0cf8b2e0da0987b.arrow\n",
      "Loading cached processed dataset at /home/gabriel.talasso/.cache/huggingface/datasets/CohereForAI___parquet/default-dc0ecc36655ce556/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-856d61da81906460.arrow\n"
     ]
    }
   ],
   "source": [
    "test_dataset = load_eval_data(DATASET_NAME, EVALSET_LEN, ['English'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def format_instruction(instruction, response, eos):\n",
    "    template = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{} \n",
    "\n",
    "### Response: {}{}\"\"\"\n",
    "\n",
    "    return template.format(instruction, response, eos)\n",
    "\n",
    "def calculate_perplexity(model, tokenizer, dataset, max_length=512):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_length = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(dataset):\n",
    "            # Format the input as an instruction\n",
    "            input_text = format_instruction(item['inputs'], item['targets'],'')\n",
    "\n",
    "            response = item['targets']\n",
    "            #response = f'\\n### Response: {response}'\n",
    "            \n",
    "            encodings = tokenizer(input_text, return_tensors='pt', truncation=True, max_length=max_length)\n",
    "            response_encodings = tokenizer(response, return_tensors='pt', truncation=True, max_length=max_length)\n",
    "\n",
    "            response_len = response_encodings.input_ids.size(1)\n",
    "\n",
    "            input_ids = encodings.input_ids.to(model.device)\n",
    "            target_ids = input_ids.clone()\n",
    "            target_ids[:, :-response_len] = -100\n",
    "\n",
    "            #print(tokenizer.decode(target_ids[0, -response_len:]))\n",
    "            \n",
    "            outputs = model(input_ids, labels=target_ids)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return torch.exp(torch.tensor(total_loss/ len(dataset))).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALSET_LEN = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ['output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/checkpoint-1',\n",
    "         'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/checkpoint-10',\n",
    "         'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/checkpoint-50',\n",
    "         'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/cluster_0_checkpoint-100',\n",
    "         'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/cluster_1_checkpoint-100',\n",
    "         'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/cluster_2_checkpoint-100',\n",
    "         'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/cluster_3_checkpoint-100',\n",
    "         'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/cluster_4_checkpoint-100',\n",
    "         'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/cluster_0_checkpoint-150',\n",
    "         'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/cluster_1_checkpoint-150',\n",
    "         'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/cluster_2_checkpoint-150',\n",
    "         'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/cluster_3_checkpoint-150',\n",
    "         'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/cluster_4_checkpoint-150',\n",
    "         'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/cluster_0_checkpoint-200',\n",
    "         'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/cluster_1_checkpoint-200',\n",
    "         'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/cluster_2_checkpoint-200',\n",
    "         'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/cluster_3_checkpoint-200',\n",
    "         'output/aya_dataset_400000_clustered_c20s2_i10_b16a1_l512_r8a16_20241002153817/cluster_4_checkpoint-200']\n",
    "\n",
    "languages  = ['English', 'Swedish', 'German', 'Portuguese', 'Spanish']\n",
    "results = []\n",
    "df = pd.DataFrame(columns=['model', 'language', 'ppl'])\n",
    "\n",
    "#for language in languages:\n",
    "#    for path in paths:\n",
    "#        model, tokenizer = load_model(path, MODEL_NAME, DEVICE)\n",
    "#        test_dataset = load_eval_data(DATASET_NAME, EVALSET_LEN, language)\n",
    "#\n",
    "#        perplexity = calculate_perplexity(model, tokenizer, test_dataset, max_length=512)\n",
    "#\n",
    "#        model_eval = path.split('/')[-1]\n",
    "#        round = path.split('-')[-1]\n",
    "#        print(f'Perplexity {model_eval}: {perplexity}')\n",
    "#\n",
    "#        results.append({'model': model_eval, 'round': round, 'language': language[0], 'ppl': perplexity})\n",
    "#\n",
    "#    df = pd.DataFrame(results)\n",
    "#    df.to_csv('results/perplexity_fedavg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_language(model): #this code is valid for a specific experiment\n",
    "\n",
    "    try:\n",
    "        if model.split('_')[1] == '0':\n",
    "            cluster_language = 'Swedish'\n",
    "\n",
    "        elif model.split('_')[1] == '1':\n",
    "            cluster_language = 'English'\n",
    "\n",
    "        elif model.split('_')[1] == '2':\n",
    "            cluster_language = 'German'\n",
    "\n",
    "        elif model.split('_')[1] == '3':\n",
    "            cluster_language = 'Portuguese'\n",
    "\n",
    "        elif model.split('_')[1] == '4':\n",
    "            cluster_language = 'Spanish'\n",
    "\n",
    "        else:\n",
    "            cluster_language = '-'\n",
    "    \n",
    "    except IndexError:\n",
    "        cluster_language = '-'\n",
    "\n",
    "    return cluster_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>test_language</th>\n",
       "      <th>English</th>\n",
       "      <th>German</th>\n",
       "      <th>Portuguese</th>\n",
       "      <th>Swedish</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>English</th>\n",
       "      <td>5.194729</td>\n",
       "      <td>6.580256</td>\n",
       "      <td>5.758704</td>\n",
       "      <td>5.972532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German</th>\n",
       "      <td>5.986902</td>\n",
       "      <td>6.098965</td>\n",
       "      <td>6.998753</td>\n",
       "      <td>6.513763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Portuguese</th>\n",
       "      <td>5.333992</td>\n",
       "      <td>6.537346</td>\n",
       "      <td>5.194914</td>\n",
       "      <td>5.822595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spanish</th>\n",
       "      <td>5.476369</td>\n",
       "      <td>6.491864</td>\n",
       "      <td>5.695516</td>\n",
       "      <td>5.811633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swedish</th>\n",
       "      <td>5.461677</td>\n",
       "      <td>6.622701</td>\n",
       "      <td>5.725368</td>\n",
       "      <td>5.385089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "test_language      English    German  Portuguese   Swedish\n",
       "cluster_language                                          \n",
       "English           5.194729  6.580256    5.758704  5.972532\n",
       "German            5.986902  6.098965    6.998753  6.513763\n",
       "Portuguese        5.333992  6.537346    5.194914  5.822595\n",
       "Spanish           5.476369  6.491864    5.695516  5.811633\n",
       "Swedish           5.461677  6.622701    5.725368  5.385089"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.read_csv('results/perplexity.csv')\n",
    "\n",
    "df_results['cluster_language'] = df_results['model'].apply(lambda x: get_cluster_language(x))\n",
    "\n",
    "df_results['language'] = df_results['language'].replace({'E': 'English', 'S': 'Swedish', 'G': 'German', 'P': 'Portuguese', 'SP': 'Spanish'})\n",
    "\n",
    "df_results = df_results.rename(columns={'language': 'test_language'})\n",
    "\n",
    "df_results = df_results[df_results['round'] == 200]\n",
    "\n",
    "df_results = df_results.pivot(index='cluster_language', columns='test_language', values='ppl')\n",
    "\n",
    "df_results.to_csv('results/results_clustered.csv')\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

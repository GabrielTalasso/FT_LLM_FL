{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "sys.path.append(\".\")\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from accelerate import Accelerator\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.template import TEMPLATE_DICT\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(DATASET_NAME, tasks, eval=False):\n",
    "    if DATASET_NAME == \"databricks/databricks-dolly-15k\":\n",
    "        dataset = load_dataset(DATASET_NAME, split=\"train\")\n",
    "        dataset = dataset.train_test_split(test_size=0.2, seed=0)\n",
    "        dataset = dataset['test'] if eval else dataset['train']\n",
    "        dataset = dataset.filter(lambda x: x['category'] in tasks)\n",
    "        dataset = dataset.map(dolly_format)\n",
    "        return dataset\n",
    "\n",
    "    if DATASET_NAME == \"CohereForAI/aya_dataset\":\n",
    "        dataset = load_dataset(DATASET_NAME, split=\"train\")\n",
    "        languages = ['English', 'Swedish', 'German', 'Portuguese', 'Spanish']\n",
    "        dataset = dataset.filter(lambda x: x['language'] in languages)\n",
    "        dataset = dataset.train_test_split(test_size=0.2, seed=0)\n",
    "        dataset = dataset['test'] if eval else dataset['train']\n",
    "        tasks = [task.capitalize() for task in tasks]\n",
    "        dataset = dataset.filter(lambda x: x['language'] in tasks)\n",
    "        dataset = dataset.map(aya_format)\n",
    "        return dataset\n",
    "\n",
    "    if DATASET_NAME == 'multitask':\n",
    "        if tasks == 'boolq' or 'boolq' in tasks:\n",
    "            dataset = prepare_boolq(eval=eval).shuffle(seed=0)\n",
    "            return dataset\n",
    "        if tasks == 'webnlg' or 'webnlg' in tasks:\n",
    "            dataset = prepare_webnlg(eval=eval).shuffle(seed=0)\n",
    "            return dataset\n",
    "        if tasks == 'samsum' or 'samsum' in tasks:\n",
    "            dataset = prepare_samsum(eval=eval).shuffle(seed=0)\n",
    "            return dataset\n",
    "        if tasks == 'gigaword' or 'gigaword' in tasks:\n",
    "            dataset = prepare_gigaword(eval=eval).shuffle(seed=0)\n",
    "            return dataset\n",
    "        if tasks == 'all_tasks' or 'all_tasks' in tasks:\n",
    "            boolq = prepare_boolq(eval=eval).map(lambda x: {'instruction': x['instruction'], 'response': x['response'], 'task': 'boolq'})\n",
    "            webnlg = prepare_webnlg(eval=eval).map(lambda x: {'instruction': x['instruction'], 'response': x['response'], 'task': 'webnlg'})\n",
    "            samsum = prepare_samsum(eval=eval).map(lambda x: {'instruction': x['instruction'], 'response': x['response'], 'task': 'samsum'})\n",
    "            gigaword = prepare_gigaword(eval=eval).map(lambda x: {'instruction': x['instruction'], 'response': x['response'], 'task': 'gigaword'})\n",
    "            dataset = concatenate_datasets([boolq, webnlg, samsum, gigaword]).shuffle(seed=0)\n",
    "            return dataset\n",
    "\n",
    "def prepare_webnlg(eval=False):\n",
    "    dataset = load_dataset('GEM/web_nlg', 'en', split='train')\n",
    "    dataset = dataset.train_test_split(test_size=0.2, seed=0)\n",
    "    dataset = dataset['test'] if eval else dataset['train']\n",
    "    dataset = dataset.map(webnlg_format)\n",
    "    return dataset\n",
    "\n",
    "def prepare_boolq(eval=False):\n",
    "    dataset = load_dataset('google/boolq', split='train')\n",
    "    dataset = dataset.train_test_split(test_size=0.2, seed=0)\n",
    "    dataset = dataset['test'] if eval else dataset['train']\n",
    "    dataset = dataset.map(boolq_format)\n",
    "    return dataset\n",
    "\n",
    "def prepare_samsum(eval=False):\n",
    "    dataset = load_dataset('Samsung/samsum', split='train', trust_remote_code=True)\n",
    "    dataset = dataset.train_test_split(test_size=0.2, seed=0)\n",
    "    dataset = dataset['test'] if eval else dataset['train']\n",
    "    dataset = dataset.map(samsum_format)\n",
    "    return dataset\n",
    "\n",
    "def prepare_gigaword(eval=False):\n",
    "    dataset = load_dataset('Harvard/gigaword', split='train', trust_remote_code=True)\n",
    "    dataset = dataset.train_test_split(test_size=0.2, seed=0)\n",
    "    dataset = dataset['test'] if eval else dataset['train']\n",
    "    dataset = dataset.shuffle(seed=0)\n",
    "    dataset = dataset.select(range(30000))\n",
    "    dataset = dataset.map(gigaword_format)\n",
    "    return dataset\n",
    "\n",
    "def boolq_format(example):\n",
    "    #example[\"instruction\"] = example['passage'] + \" Based on the passage, answer this question:\" + example['question']\n",
    "    example[\"instruction\"] = example['passage'] + '-' + example['question']\n",
    "    example[\"response\"] = str(example['answer'])\n",
    "    return example\n",
    "\n",
    "def webnlg_format(example):\n",
    "    example['input'] = str(example['input'])\n",
    "    #example[\"instruction\"] = \"Organize this data into a readable text: \" + example['input']\n",
    "    example[\"instruction\"] = example['input']\n",
    "    example[\"response\"] = example['target']\n",
    "    return example\n",
    "\n",
    "def samsum_format(example):\n",
    "    #example[\"instruction\"] = \"Summarize this conversation: \" + example['dialogue']\n",
    "    example[\"instruction\"] = example['dialogue']\n",
    "    example[\"response\"] = example['summary']\n",
    "    return example\n",
    "\n",
    "def gigaword_format(example):\n",
    "    #example[\"instruction\"] = \"Summarize this text: \" + example['document']\n",
    "    example[\"instruction\"] = example['document']\n",
    "    example[\"response\"] = example['summary']\n",
    "    return example\n",
    "\n",
    "def dolly_format(example):\n",
    "    if example['context'] == \"\":\n",
    "        example[\"inputs\"] = example[\"instruction\"]\n",
    "    else:\n",
    "        example[\"inputs\"] = example[\"instruction\"] + \" \" + example['context']\n",
    "    return example\n",
    "\n",
    "def aya_format(example):\n",
    "    example[\"instruction\"] = example['inputs']\n",
    "    example[\"response\"] = example['targets']\n",
    "    return example\n",
    "\n",
    "alpaca_template = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{} \n",
    "\n",
    "### Response: {}{}\"\"\"\n",
    "\n",
    "TEMPLATE_DICT = {\n",
    "    'alpaca': (alpaca_template, '\\n### Response:'),\n",
    "}\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples[\"inputs\"], return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
    "    targets = inputs.copy()\n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
    "        \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
    "        \"labels\": targets[\"input_ids\"].squeeze()\n",
    "    }\n",
    "\n",
    "def format_instruction(instruction, response, eos):\n",
    "    template = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{} \n",
    "\n",
    "### Response: {}{}\"\"\"\n",
    "    return template.format(instruction, response, eos)\n",
    "\n",
    "def apply_template_to_dataset(dataset):\n",
    "    dataset = dataset.map(lambda x: {'inputs': format_instruction(x, '', '')})\n",
    "    return dataset\n",
    "\n",
    "def get_formatting_prompts_func_test(template_name, eos_token):\n",
    "    if template_name in TEMPLATE_DICT:\n",
    "        overall_temp, response_temp = TEMPLATE_DICT[template_name]\n",
    "        def formatting_prompts_func(example):    \n",
    "            text = overall_temp.format(example['instruction'], '', '')\n",
    "            return text\n",
    "    elif template_name == 'ag_news':\n",
    "        formatting_prompts_func = None\n",
    "        response_temp = None\n",
    "    return formatting_prompts_func, response_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, MODEL_NAME, DEVICE = 'cuda'):\n",
    "    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.float16,\n",
    "                                                    quantization_config = BitsAndBytesConfig(\n",
    "                                                                            load_in_4bit=True,\n",
    "                                                                            bnb_4bit_use_double_quant=True,\n",
    "                                                                            bnb_4bit_quant_type=\"nf4\",\n",
    "                                                                            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                                                                        ),\n",
    "                                                    device_map={\"\": Accelerator().local_process_index})\n",
    "\n",
    "    model = PeftModel.from_pretrained(model, path).to(DEVICE)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, device=DEVICE, use_fast=False, padding_side=\"left\")\n",
    "    #tokenizer.pad_token = tokenizer.unk_token\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name  =  'unsloth/Llama-3.2-1B'\n",
    "cluster, round = 3, 200\n",
    "\n",
    "model_path  =  f'/home/gabriel.talasso/FT_LLM_FL/output_multitask/SmolLM-360M/wo_formatting_fedavg_multitask_clustered_c20s5_i10_b16a1_l1024_r8a16_20250331161819/cluster_{cluster}_checkpoint-{round}'\n",
    "model_path =   f'/home/gabriel.talasso/FT_LLM_FL/output_multitask/SmolLM-360M/wo_formatting_clustered_multitask_clustered_c20s5_i10_b16a1_l1024_r8a16_20250331134834/cluster_{cluster}_checkpoint-{round}'\n",
    "model_path = '/home/gabriel.talasso/FT_LLM_FL/output_multitask/Llama-3.2-1B/clustered_multitask_clustered_c20s5_i10_b16a1_l1024_r8a16_20250401151553/cluster_0_checkpoint-200'\n",
    "#model_path = '/home/gabriel.talasso/FT_LLM_FL/output_multitask/Llama-3.2-1B/fedavg_multitask_clustered_c20s5_i10_b16a1_l1024_r8a16_20250401152254/cluster_0_checkpoint-200'\n",
    "\n",
    "model, tokenizer = load_model(model_path, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data('multitask', 'boolq', eval=True)\n",
    "formatting_prompts_func, _ = get_formatting_prompts_func_test('alpaca', '\\n### Response:')\n",
    "dataset = dataset.map(lambda x: {'inputs': formatting_prompts_func(x), 'targets': x['response']})\n",
    "dataset = dataset.shuffle(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.25it/s]\n"
     ]
    }
   ],
   "source": [
    "def generate_response(model, tokenizer, dataset):\n",
    "    model.eval()\n",
    "    responses = []\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        inputs = dataset[i]['inputs']\n",
    "        inputs = tokenizer(inputs, return_tensors='pt', max_length=512).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, max_new_tokens=128, do_sample=False, eos_token_id=tokenizer.eos_token_id, pad_token_id=tokenizer.pad_token_id)\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        responses.append(response)\n",
    "        #print(f\"Example {i}:\")\n",
    "        #print(f\"Instruction: {dataset[i]['inputs']}\")\n",
    "        #print(f\"Response: {response}\")\n",
    "        #print(\"-\" * 50)\n",
    "    return responses\n",
    "\n",
    "responses = generate_response(model, tokenizer, dataset)\n",
    "dataset = dataset.add_column('responses', responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nAn offensive strategy would be holding on to Wild and Wild Draw Four cards because they can be played near the end of the hand in order to go out (when it's harder to play a matching card). However, a defensive strategy would advise getting rid of such cards early, because they have a high point value.-can you hold a draw four in uno \\n\\n### Response:  False\",\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nBen Nevis (Scottish Gaelic: Beinn Nibheis, pronounced (peˈɲivəʃ); English: /bɛnˈnɛvɪs/) is the highest mountain in the British Isles, located in Scotland. Standing at 1,345 metres (4,411 ft) above sea level, it is located at the western end of the Grampian Mountains in the Lochaber area of the Scottish Highlands, close to the town of Fort William.-is ben nevis the highest mountain in britain \\n\\n### Response: 1,345 m (4,411 ft)',\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nIn May 2017, Netflix renewed 13 Reasons Why for a second season; filming began the next month and concluded that December. The second season was released on May 18, 2018, and received negative reviews from critics and mixed reviews from audiences. A third season was ordered in June 2018 and is set to be released in 2019. Critical and audience reaction to the series has been divided, with the program generating controversy between audiences and industry reviewers.-does 13 reasons why have a season 2 \\n\\n### Response: 13 Reasons Why has a second season',\n",
       " \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSilicon Valley (abbreviated as SV) is a region in the southern San Francisco Bay Area of Northern California, referring to the Santa Clara Valley, which serves as the global center for high technology, venture capital, innovation, and social media. San Jose is the Valley's largest city, the 3rd-largest in California, and the 10th-largest in the United States. Other major SV cities include Palo Alto, Santa Clara, Mountain View, and Sunnyvale. The San Jose Metropolitan Area has the third highest GDP per capita in the world (after Zurich, Switzerland and Oslo, Norway), according to the Brookings Institution.-is silicon valley part of the bay area \\n\\n### Response:  Silicon Valley is a region in the southern San Francisco Bay Area of Northern California.\",\n",
       " \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSoft-shell crab is a culinary term for crabs that have recently molted their old exoskeleton and are still soft. Soft-shells are removed from the water as soon as they molt to prevent any hardening of their shell. This means that almost the entire animal can be eaten, rather than having to shell the animal to reach the meat. The exceptions are the mouthparts, the gills and the abdomen, which, though edible when shells are very soft, are usually discarded (``cleaned''). The remaining, edible part of the crab is typically deep fried or sautéed.-do you eat the shell on soft shell crab \\n\\n### Response:  True\",\n",
       " \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDance Academy is an Australian children's television drama. The show aired on ABC1 and ABC3 in Australia, and on ZDF in Germany. Series one premiered in Australia on 31 May 2010, the second series began on 12 March 2012, and series three began on 8 July 2013.-is there a season 3 of dance academy \\n\\n### Response:  True\",\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nIn the Second Party Congress vote, the Bolsheviks won on the majority of important issues, hence their name. They ultimately became the Communist Party of the Soviet Union. The Bolsheviks, or Reds, came to power in Russia during the October Revolution phase of the Russian Revolution of 1917 and founded the Russian Soviet Federative Socialist Republic (RSFSR). With the Reds defeating the Whites and others during the Russian Civil War of 1917--1922, the RSFSR became the chief constituent of the Soviet Union (USSR) in December 1922.-are the bolsheviks the same as the soviets \\n\\n### Response:  True',\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nThe second season of the American cable television series Legion is based on the Marvel Comics character David Haller / Legion, a mutant diagnosed with schizophrenia at a young age. The season is connected to the X-Men film series, and is produced by FX Productions in association with Marvel Television. Noah Hawley serves as showrunner.-will there be a season 2 of legion \\n\\n### Response: ',\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nThe LRV was transported to the Moon on the Apollo Lunar Module (LM) and, once unpacked on the surface, could carry one or two astronauts, their equipment, and lunar samples. The three LRVs remain on the Moon.-did we leave the lunar rover on the moon \\n\\n### Response:  True',\n",
       " \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nThe signing of the Residence Act on July 16, 1790, approved the creation of a capital district located along the Potomac River on the country's East Coast. The U.S. Constitution provided for a federal district under the exclusive jurisdiction of the Congress and the District is therefore not a part of any state. The states of Maryland and Virginia each donated land to form the federal district, which included the pre-existing settlements of Georgetown and Alexandria. Named in honor of President George Washington, the City of Washington was founded in 1791 to serve as the new national capital. In 1846, Congress returned the land originally ceded by Virginia; in 1871, it created a single municipal government for the remaining portion of the District.-is washington dc a state in the united states \\n\\n### Response:  False\"]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9846728933444713)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rouge score between the responses and the targets for all examples\n",
    "from evaluate import load\n",
    "\n",
    "rouge_metric = load(\"rouge\")\n",
    "predictions = dataset['responses']\n",
    "references = [inp + tar for inp, tar in zip(dataset['inputs'], dataset['targets'])]\n",
    "results = rouge_metric.compute(predictions=predictions, references=references, use_stemmer=True)\n",
    "rouge1 = results['rouge1']\n",
    "rouge1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rouge score between the responses and the targets for all examples\n",
    "from evaluate import load\n",
    "\n",
    "rouge_metric = load(\"rouge\")\n",
    "predictions = [inp.split('### Response: ')[1] for inp in dataset['responses']]\n",
    "references = [tar for tar in  dataset['targets']]\n",
    "\n",
    "\n",
    "results = rouge_metric.compute(predictions=predictions, references=references, use_stemmer=True)\n",
    "rouge1 = results['rouge1']\n",
    "rouge1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "\n",
    "predictions = dataset['responses']\n",
    "references = [inp + tar for inp, tar in zip(dataset['inputs'], dataset['targets'])]\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "rouge1_scores_precision = [scorer.score(ref, pred)['rouge1'] .precision for ref, pred in zip(references, predictions)]\n",
    "rouge1_scores_recall = [scorer.score(ref, pred)['rouge1'].recall for ref, pred in zip(references, predictions)]\n",
    "rouge1_scores = [scorer.score(ref, pred)['rouge1'].fmeasure for ref, pred in zip(references, predictions)]\n",
    "\n",
    "rouge1_precision = np.mean(rouge1_scores_precision)\n",
    "rouge1_recall = np.mean(rouge1_scores_recall)\n",
    "rouge1_fmeasure = np.mean(rouge1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 Precision: 0.9754298178601584\n",
      "Rouge-1 Recall: 0.9947377168503424\n",
      "Rouge-1 F-measure: 0.9846728933444713\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rouge-1 Precision: {rouge1_precision}\")\n",
    "print(f\"Rouge-1 Recall: {rouge1_recall}\")\n",
    "print(f\"Rouge-1 F-measure: {rouge1_fmeasure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nAn offensive strategy would be holding on to Wild and Wild Draw Four cards because they can be played near the end of the hand in order to go out (when it's harder to play a matching card). However, a defensive strategy would advise getting rid of such cards early, because they have a high point value.-can you hold a draw four in uno \\n\\n### Response:  False\",\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nBen Nevis (Scottish Gaelic: Beinn Nibheis, pronounced (peˈɲivəʃ); English: /bɛnˈnɛvɪs/) is the highest mountain in the British Isles, located in Scotland. Standing at 1,345 metres (4,411 ft) above sea level, it is located at the western end of the Grampian Mountains in the Lochaber area of the Scottish Highlands, close to the town of Fort William.-is ben nevis the highest mountain in britain \\n\\n### Response: 1,345 m (4,411 ft)',\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nIn May 2017, Netflix renewed 13 Reasons Why for a second season; filming began the next month and concluded that December. The second season was released on May 18, 2018, and received negative reviews from critics and mixed reviews from audiences. A third season was ordered in June 2018 and is set to be released in 2019. Critical and audience reaction to the series has been divided, with the program generating controversy between audiences and industry reviewers.-does 13 reasons why have a season 2 \\n\\n### Response: 13 Reasons Why has a second season',\n",
       " \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSilicon Valley (abbreviated as SV) is a region in the southern San Francisco Bay Area of Northern California, referring to the Santa Clara Valley, which serves as the global center for high technology, venture capital, innovation, and social media. San Jose is the Valley's largest city, the 3rd-largest in California, and the 10th-largest in the United States. Other major SV cities include Palo Alto, Santa Clara, Mountain View, and Sunnyvale. The San Jose Metropolitan Area has the third highest GDP per capita in the world (after Zurich, Switzerland and Oslo, Norway), according to the Brookings Institution.-is silicon valley part of the bay area \\n\\n### Response:  Silicon Valley is a region in the southern San Francisco Bay Area of Northern California.\",\n",
       " \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nSoft-shell crab is a culinary term for crabs that have recently molted their old exoskeleton and are still soft. Soft-shells are removed from the water as soon as they molt to prevent any hardening of their shell. This means that almost the entire animal can be eaten, rather than having to shell the animal to reach the meat. The exceptions are the mouthparts, the gills and the abdomen, which, though edible when shells are very soft, are usually discarded (``cleaned''). The remaining, edible part of the crab is typically deep fried or sautéed.-do you eat the shell on soft shell crab \\n\\n### Response:  True\",\n",
       " \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDance Academy is an Australian children's television drama. The show aired on ABC1 and ABC3 in Australia, and on ZDF in Germany. Series one premiered in Australia on 31 May 2010, the second series began on 12 March 2012, and series three began on 8 July 2013.-is there a season 3 of dance academy \\n\\n### Response:  True\",\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nIn the Second Party Congress vote, the Bolsheviks won on the majority of important issues, hence their name. They ultimately became the Communist Party of the Soviet Union. The Bolsheviks, or Reds, came to power in Russia during the October Revolution phase of the Russian Revolution of 1917 and founded the Russian Soviet Federative Socialist Republic (RSFSR). With the Reds defeating the Whites and others during the Russian Civil War of 1917--1922, the RSFSR became the chief constituent of the Soviet Union (USSR) in December 1922.-are the bolsheviks the same as the soviets \\n\\n### Response:  True',\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nThe second season of the American cable television series Legion is based on the Marvel Comics character David Haller / Legion, a mutant diagnosed with schizophrenia at a young age. The season is connected to the X-Men film series, and is produced by FX Productions in association with Marvel Television. Noah Hawley serves as showrunner.-will there be a season 2 of legion \\n\\n### Response: ',\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nThe LRV was transported to the Moon on the Apollo Lunar Module (LM) and, once unpacked on the surface, could carry one or two astronauts, their equipment, and lunar samples. The three LRVs remain on the Moon.-did we leave the lunar rover on the moon \\n\\n### Response:  True',\n",
       " \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nThe signing of the Residence Act on July 16, 1790, approved the creation of a capital district located along the Potomac River on the country's East Coast. The U.S. Constitution provided for a federal district under the exclusive jurisdiction of the Congress and the District is therefore not a part of any state. The states of Maryland and Virginia each donated land to form the federal district, which included the pre-existing settlements of Georgetown and Alexandria. Named in honor of President George Washington, the City of Washington was founded in 1791 to serve as the new national capital. In 1846, Congress returned the land originally ceded by Virginia; in 1871, it created a single municipal government for the remaining portion of the District.-is washington dc a state in the united states \\n\\n### Response:  False\"]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-1 Precision: 0.5\n",
      "Rouge-1 Recall: 0.5\n",
      "Rouge-1 F-measure: 0.5\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "\n",
    "predictions = [inp.split('### Response: ')[1] for inp in dataset['responses']]\n",
    "references = [tar for tar in  dataset['targets']]\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "rouge1_scores_precision = [scorer.score(ref, pred)['rouge1'] .precision for ref, pred in zip(references, predictions)]\n",
    "rouge1_scores_recall = [scorer.score(ref, pred)['rouge1'].recall for ref, pred in zip(references, predictions)]\n",
    "rouge1_scores = [scorer.score(ref, pred)['rouge1'].fmeasure for ref, pred in zip(references, predictions)]\n",
    "\n",
    "rouge1_precision = np.mean(rouge1_scores_precision)\n",
    "rouge1_recall = np.mean(rouge1_scores_recall)\n",
    "rouge1_fmeasure = np.mean(rouge1_scores)\n",
    "\n",
    "print(f\"Rouge-1 Precision: {rouge1_precision}\")\n",
    "print(f\"Rouge-1 Recall: {rouge1_recall}\")\n",
    "print(f\"Rouge-1 F-measure: {rouge1_fmeasure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' False',\n",
       " '1,345 m (4,411 ft)',\n",
       " '13 Reasons Why has a second season',\n",
       " ' Silicon Valley is a region in the southern San Francisco Bay Area of Northern California.',\n",
       " ' True',\n",
       " ' True',\n",
       " ' True',\n",
       " '',\n",
       " ' True',\n",
       " ' False']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967541864438604"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.967541864438604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8757830833830799"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.743116414089967\n",
    "0.7240112512226433\n",
    "0.743116414089967\n",
    "0.8757830833830799"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fedavg\n",
    "\n",
    "Rouge-1 Precision: 0.6004595779970863\n",
    "\n",
    "Rouge-1 Recall: 0.9911330291403916\n",
    "\n",
    "Rouge-1 F-measure: 0.7386883505534914\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 3\n",
    "\n",
    "Rouge-1 Precision: 0.43991448171893444\n",
    "\n",
    "Rouge-1 Recall: 1.0\n",
    "\n",
    "Rouge-1 F-measure: 0.6084780128127207\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5503595346990156"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.6191708966090461\n",
    "0.5503595346990156"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
